{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SODOKU ReinforceLearning :3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mated\\anaconda3\\envs\\torch_tesseract\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se está utilizando el dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Se está utilizando el dispositivo:', device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_board(board):\n",
    "#     encoded_board = np.zeros((9, 9, 10))\n",
    "#     # encoded_board = np.zeros((1, 9, 9))\n",
    "#     for i in range(9):\n",
    "#         for j in range(9):\n",
    "#             if board[i, j] != 0:\n",
    "#                 encoded_board[i, j, board[i, j] - 1] = 1\n",
    "#             else:\n",
    "#                 encoded_board[i, j, 9] = 1\n",
    "#     return encoded_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_board(board):\n",
    "    encoded_board = np.zeros((1, 9, 9, 10))  # Agregamos una dimensión adicional al principio\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            if board[i, j] != 0:\n",
    "                encoded_board[0, i, j, board[i, j] - 1] = 1  # Indexamos con la dimensión adicional\n",
    "            else:\n",
    "                encoded_board[0, i, j, 9] = 1\n",
    "    # return encoded_board\n",
    "    return encoded_board[np.newaxis, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RED NEURONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pueden ser otras estructuras, peor por primer ejemplo tomamos esta :3\n",
    "class SudokuDQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SudokuDQN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=(9, 3, 3), padding=(0, 1, 1))\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(64, 64, kernel_size=(1, 3, 3), padding=(0, 1, 1))\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv3d(64, 64, kernel_size=(1, 3, 3), padding=(0, 1, 1))\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(64 * 9 * 10, 81)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        print('Shape conv x :', x.shape)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        print('Shape view x :', x.shape)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        print('Shape fc x :', x.shape)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, model, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.randint(0, 8)  # acción aleatoria\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            q_values = model(state)\n",
    "            return q_values.argmax().item()  # mejor acción según los valores Q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SudokuDQN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape conv x : torch.Size([2, 64, 1, 9, 10])\n",
      "Shape view x : torch.Size([2, 5760])\n",
      "Shape fc x : torch.Size([2, 81])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1         [-1, 64, 1, 9, 10]           5,248\n",
      "              ReLU-2         [-1, 64, 1, 9, 10]               0\n",
      "            Conv3d-3         [-1, 64, 1, 9, 10]          36,928\n",
      "              ReLU-4         [-1, 64, 1, 9, 10]               0\n",
      "            Conv3d-5         [-1, 64, 1, 9, 10]          36,928\n",
      "              ReLU-6         [-1, 64, 1, 9, 10]               0\n",
      "            Linear-7                   [-1, 81]         466,641\n",
      "================================================================\n",
      "Total params: 545,745\n",
      "Trainable params: 545,745\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.26\n",
      "Params size (MB): 2.08\n",
      "Estimated Total Size (MB): 2.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "encoded_board = encode_board(np.zeros((9, 9)))\n",
    "input_dim = encoded_board.shape\n",
    "\n",
    "summary(model, input_size=input_dim[1:], batch_size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de muestreo de acción basada en probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_action(prob_dist):\n",
    "    action = torch.multinomial(prob_dist, 1).item()\n",
    "    return action"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento con RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sudoku import Sudoku\n",
    "\n",
    "def generate_sudoku(difficulty='easy'):\n",
    "    if difficulty == 'easy':\n",
    "        difficulty_value = 0.2\n",
    "    elif difficulty == 'medium':\n",
    "        difficulty_value = 0.5\n",
    "    elif difficulty == 'hard':\n",
    "        difficulty_value = 0.7\n",
    "    else:\n",
    "        raise ValueError(\"Invalid difficulty level\")\n",
    "    \n",
    "    puzzle = Sudoku(difficulty=difficulty_value)\n",
    "    board = puzzle.board\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[None, None, None, None, None, None, None, None, 9],\n",
       " [None, None, None, None, None, None, 7, None, None],\n",
       " [None, 2, None, None, None, None, None, None, None],\n",
       " [None, None, None, None, None, None, None, 8, None],\n",
       " [None, None, None, 4, None, None, None, None, None],\n",
       " [None, None, None, None, None, 6, None, None, None],\n",
       " [None, None, None, None, 5, None, None, None, None],\n",
       " [1, None, None, None, None, None, None, None, None],\n",
       " [None, None, 3, None, None, None, None, None, None]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sudoku()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1, 9, 9, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mated\\AppData\\Local\\Temp\\ipykernel_26896\\3003830709.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encoded_board = torch.tensor(encoded_board, dtype=torch.float32).unsqueeze(0).to(device)  # Agrega la dimensión de batch y mueve el tensor al dispositivo\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4D (unbatched) or 5D (batched) input to conv3d, but got input of size: [1, 1, 1, 1, 9, 9, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# Jugar un episodio completo de Sudoku\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_steps):\n\u001b[1;32m---> 20\u001b[0m     prob_dist \u001b[39m=\u001b[39m model(encoded_board)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)  \u001b[39m# Obtiene la distribución de probabilidad de las acciones\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     action \u001b[39m=\u001b[39m sample_action(prob_dist)  \u001b[39m# Muestrea una acción de la distribución de probabilidad\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     next_board, reward, done \u001b[39m=\u001b[39m step(board, action)  \u001b[39m# Asume que la función `step()` aplica la acción en el tablero y devuelve el nuevo tablero, la recompensa y si el juego terminó\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mated\\anaconda3\\envs\\torch_tesseract\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m, in \u001b[0;36mSudokuDQN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 14\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))\n\u001b[0;32m     15\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n\u001b[0;32m     16\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x))\n",
      "File \u001b[1;32mc:\\Users\\mated\\anaconda3\\envs\\torch_tesseract\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mated\\anaconda3\\envs\\torch_tesseract\\lib\\site-packages\\torch\\nn\\modules\\conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\mated\\anaconda3\\envs\\torch_tesseract\\lib\\site-packages\\torch\\nn\\modules\\conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    597\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv3d(\n\u001b[0;32m    598\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[0;32m    599\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[0;32m    607\u001b[0m     )\n\u001b[1;32m--> 608\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv3d(\n\u001b[0;32m    609\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[0;32m    610\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 4D (unbatched) or 5D (batched) input to conv3d, but got input of size: [1, 1, 1, 1, 9, 9, 10]"
     ]
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "gamma = 0.99  # factor de descuento\n",
    "max_steps = 200\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    board = np.array(generate_sudoku()).astype('float32')\n",
    "    board[np.isnan(board)] = 0\n",
    "    board = board.astype('int')\n",
    "    encoded_board = encode_board(board)\n",
    "    encoded_board = torch.tensor(encoded_board, dtype=torch.float32).unsqueeze(0).to(device)  # Agrega la dimensión de batch y mueve el tensor al dispositivo\n",
    "    print(encoded_board.shape)\n",
    "\n",
    "\n",
    "    encoded_board = torch.tensor(encoded_board, dtype=torch.float32).unsqueeze(0).to(device)  # Agrega la dimensión de batch y mueve el tensor al dispositivo\n",
    "    log_probs = []\n",
    "    rewards = []\n",
    "\n",
    "    # Jugar un episodio completo de Sudoku\n",
    "    for t in range(max_steps):\n",
    "        prob_dist = model(encoded_board).cpu().detach().squeeze(0)  # Obtiene la distribución de probabilidad de las acciones\n",
    "        action = sample_action(prob_dist)  # Muestrea una acción de la distribución de probabilidad\n",
    "\n",
    "        next_board, reward, done = step(board, action)  # Asume que la función `step()` aplica la acción en el tablero y devuelve el nuevo tablero, la recompensa y si el juego terminó\n",
    "        rewards.append(reward)\n",
    "        log_prob = torch.log(prob_dist[action])\n",
    "        log_probs.append(log_prob)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        board = next_board\n",
    "        encoded_board = encode_board(board)\n",
    "        encoded_board = torch.tensor(encoded_board, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    # Calcula la pérdida y actualiza los pesos del modelo\n",
    "    G = 0\n",
    "    loss = 0\n",
    "    for t in reversed(range(len(rewards))):\n",
    "        G = gamma * G + rewards[t]\n",
    "        loss -= log_probs[t] * G\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f'Episodio {episode + 1}, pérdida: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_tesseract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
